{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got features for 0.jpg\n",
      "got features for 1.jpg\n",
      "got features for 2.jpg\n",
      "got features for 3.jpg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()  \n",
    "flann_params = dict(algorithm = 1, trees = 5)     \n",
    "matcher = cv2.FlannBasedMatcher(flann_params, {})\n",
    "bow_extract  =cv2.BOWImgDescriptorExtractor(sift,matcher)\n",
    "\n",
    "def grab(image):\n",
    "\n",
    "    img = cv2.imread(image)\n",
    "    \n",
    "    mask = np.zeros(img.shape[:2],np.uint8)\n",
    "\n",
    "    bgdModel = np.zeros((1,65),np.float64)\n",
    "    fgdModel = np.zeros((1,65),np.float64)\n",
    "    \n",
    "    rect = (int(img.shape[0]*0.1),int(img.shape[1]*0.1),int(img.shape[0]*0.9),int(img.shape[1]*0.9))\n",
    "\n",
    "    cv2.grabCut(img,mask,rect,bgdModel,fgdModel,1,cv2.GC_INIT_WITH_RECT)\n",
    "    mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "    img = img*mask2[:,:,np.newaxis]\n",
    "    \n",
    "    return img\n",
    "\n",
    "def trainVocab(descriptors):\n",
    "\n",
    "#   change this to exceed the descriptor entry number by 2\n",
    "    bow_train = cv2.BOWKMeansTrainer(20)\n",
    "    \n",
    "    for des in descriptors:\n",
    "        bow_train.add(des)\n",
    "        \n",
    "    vocab = bow_train.cluster()\n",
    "    bow_extract.setVocabulary(vocab)\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "def train(trainData, bow_extract, img, svmModel, dog):\n",
    "    \n",
    "    kp = sift.detect(img, None)\n",
    "    \n",
    "    # sort keypoints based on response\n",
    "    kp = sorted(kp, key = lambda x:x.response)\n",
    "    \n",
    "    if(len(kp)>= 10):\n",
    "\n",
    "        # compute descriptors for only the 10 keypoints with best responses for each image\n",
    "        \n",
    "        featureSet = bow_extract.compute(img, kp[:10])\n",
    "        trainData.extend(featureSet)\n",
    "        svmModel.append(dog)\n",
    "\n",
    "    \n",
    "def getFeatures(img, descriptors):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    # detect keypoints first\n",
    "    kp = sift.detect(img,None)\n",
    "\n",
    "    # sort keypoints based on response\n",
    "    kp = sorted(kp, key = lambda x:x.response)\n",
    "    \n",
    "    if(len(kp)>= 10):\n",
    "\n",
    "        # compute descriptors for only the 10 keypoints with best responses for each image\n",
    "        kp, des = sift.compute(img, kp[:10])\n",
    "    \n",
    "        descriptors.extend(des)\n",
    "\n",
    "def predict(voc, clf):\n",
    "\n",
    "    bow_extract.setVocabulary(voc)\n",
    "\n",
    "    testFolder = \"C:/Users/Isaac/Pictures/X_Test/\"\n",
    "\n",
    "    for root, dirs, files in os.walk(testFolder):\n",
    "\n",
    "        for file in files:\n",
    "                \n",
    "            result = \"UNSURE\"\n",
    "            imgPath = (testFolder + file)\n",
    "            img = grab(imgPath)\n",
    "            original = cv2.imread(imgPath)\n",
    "            featureset = bow_extract.compute(img, sift.detect(img))\n",
    "\n",
    "            prediction = clf.predict(featureset)\n",
    "            \n",
    "            if (prediction == 1):\n",
    "                with open('C:/Users/Isaac/prediction.csv', 'w') as csvfile:\n",
    "                    writer.writerow({'Image': file, 'Label': prediction})\n",
    "                result = \"DOG\"\n",
    "\n",
    "            elif (prediction == 0):\n",
    "                with open('C:/Users/Isaac/prediction.csv', 'w') as csvfile:\n",
    "                    writer.writerow({'Image': file, 'Label': prediction})\n",
    "                result = \"CAT\"\n",
    "                    \n",
    "            plt.imshow(original),plt.title(\"This is \" + result),plt.show()\n",
    "\n",
    "\n",
    "trainDir = 'C:/Users/Isaac/Pictures/X_Train/'\n",
    "descriptors = []\n",
    "trainData = []\n",
    "svmModel = []\n",
    "vocab = []\n",
    "count = 1\n",
    "\n",
    "for i in range (0,2):\n",
    "    if (i == 0):\n",
    "        with open('C:/Users/Isaac/Downloads/Y_Train.csv', newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                    \n",
    "                img = (trainDir + row['Image'])\n",
    "                img = grab(img)\n",
    "                \n",
    "                getFeatures(img, descriptors)\n",
    "                print(\"got features for \" + row['Image'])\n",
    "                count += 1\n",
    "                \n",
    "                #change this to test for smaller training set\n",
    "                if count == 100:\n",
    "                    break\n",
    "                \n",
    "        print(\"training vocab for \" + str(count) + \" images\")\n",
    "        vocab = trainVocab(descriptors)\n",
    "        \n",
    "    if (i == 1):\n",
    "        count = 1        \n",
    "        with open('C:/Users/Isaac/Downloads/Y_Train.csv', newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                    \n",
    "                img = (trainDir + row['Image'])\n",
    "                dog = 0\n",
    "                if (row['Label'] == '1'):\n",
    "                    dog = 1\n",
    "                img = grab(img)\n",
    "                count += 1\n",
    "                \n",
    "                print(\"training data with features of \" + row['Image'])\n",
    "                train(trainData, bow_extract, img, svmModel, dog)\n",
    "                \n",
    "                #change this to test for smaller training set\n",
    "                if count == 100:\n",
    "                    break\n",
    "\n",
    "with open('C:/Users/Isaac/prediction.csv', 'w') as csvfile:\n",
    "    fieldnames = ['Image', 'Label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "clf = LinearSVC()\n",
    "clf.fit(trainData, svmModel)\n",
    "predict(vocab, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
